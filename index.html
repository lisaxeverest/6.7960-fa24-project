<html>
<head>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>

<link rel="shortcut icon" href="images/icon.ico">
<style type="text/css">
	body {
		background-color: #f5f9ff;
	}

	/* Hide both math displays initially, will display based on JS detection */
  .mathjax-mobile, .mathml-non-mobile { display: none; }

  /* Show the MathML content by default on non-mobile devices */
  .show-mathml .mathml-non-mobile { display: block; }
  .show-mathjax .mathjax-mobile { display: block; }

	.content-margin-container {
		display: flex;
		width: 100%; /* Ensure the container is full width */
		justify-content: left; /* Horizontally centers the children in the container */
		align-items: center;  /* Vertically centers the children in the container */
	}
	.main-content-block {
		width: 70%; /* Change this percentage as needed */
    max-width: 1100px; /* Optional: Maximum width */
		background-color: #fff;
		border-left: 1px solid #DDD;
		border-right: 1px solid #DDD;
		padding: 8px 8px 8px 8px;
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
	}
	.margin-left-block {
			font-size: 14px;
			width: 15%; /* Change this percentage as needed */
			max-width: 130px; /* Optional: Maximum width */
			position: relative;
			margin-left: 10px;
			text-align: left;
			font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
			padding: 5px;
	}
	.margin-right-block {
			font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
			font-size: 14px;
			width: 25%; /* Change this percentage as needed */
			max-width: 256px; /* Optional: Maximum width */
			position: relative;
			text-align: left;
			padding: 10px;  /* Optional: Adds padding inside the caption */
	}

	img {
			max-width: 100%; /* Make sure it fits inside the container */
			height: auto;
			display: block;
			margin: auto;
	}
	.my-video {
			max-width: 100%; /* Make sure it fits inside the container */
			height: auto;
			display: block;
			margin: auto;
	}
	/* Hide both video displays initially, will display based on JS detection */
  .vid-mobile, .vid-non-mobile { display: none; }

  /* Show the video content by default on non-mobile devices */
  .show-vid-mobile .vid-mobile { display: block; }
  .show-vid-non-mobile .vid-non-mobile { display: block; }

	a:link,a:visited
	{
		color: #0e7862; /*#1367a7;*/
		text-decoration: none;
	}
	a:hover {
		color: #24b597; /*#208799;*/
	}

	h1 {
		font-size: 18px;
		margin-top: 4px;
		margin-bottom: 10px;
	}

	table.header {
    font-weight: 300;
    font-size: 17px;
    flex-grow: 1;
		width: 70%;
    max-width: calc(100% - 290px); /* Adjust according to the width of .paper-code-tab */
	}
	table td, table td * {
	    vertical-align: middle;
	    position: relative;
	}
	table.paper-code-tab {
	    flex-shrink: 0;
	    margin-left: 8px;
	    margin-top: 8px;
	    padding: 0px 0px 0px 8px;
	    width: 290px;
	    height: 150px;
	}

	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	hr {
    height: 1px; /* Sets the height of the line to 1 pixel */
    border: none; /* Removes the default border */
    background-color: #DDD; /* Sets the line color to black */
  }

	div.hypothesis {
		width: 80%;
		background-color: #EEE;
		border: 1px solid black;
		border-radius: 10px;
		-moz-border-radius: 10px;
		-webkit-border-radius: 10px;
		font-family: Courier;
		font-size: 18px;
		text-align: center;
		margin: auto;
		padding: 16px 16px 16px 16px;
	}

	div.citation {
    font-size: 0.8em;
    background-color:#fff;
    padding: 10px;
		height: 200px;
  }

	.fade-in-inline {
		position: absolute;
		text-align: center;
		margin: auto;
		-webkit-mask-image: linear-gradient(to right,
																			transparent 0%,
																			transparent 40%,
																			black 50%,
																			black 90%,
																			transparent 100%);
		mask-image: linear-gradient(to right,
																transparent 0%,
																transparent 40%,
																black 50%,
																black 90%,
																transparent 100%);
		-webkit-mask-size: 8000% 100%;
		mask-size: 8000% 100%;
		animation-name: sweepMask;
		animation-duration: 4s;
		animation-iteration-count: infinite;
		animation-timing-function: linear;
		animation-delay: -1s;
	}

	.fade-in2-inline {
			animation-delay: 1s;
	}

	.inline-div {
			position: relative;
	    display: inline-block; /* Makes both the div and paragraph inline-block elements */
	    vertical-align: top; /* Aligns them at the top, you can adjust this to middle, bottom, etc., based on your needs */
	    width: 50px; /* Optional: Adds space between the div and the paragraph */
	}
    table {
        width: 100%;
        border-collapse: collapse;
        margin: 20px 0;
        font-size: 16px;
        text-align: left;
    }
    table caption {
        font-weight: bold;
        margin-bottom: 10px;
        text-align: left;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    th {
        background-color: #f2f2f2;
        text-align: center;
    }
    tr:nth-child(even) {
        background-color: #f9f9f9;
    }
    tr:hover {
        background-color: #f1f1f1;
    }
</style>
	
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


	  <title>Prescriptive neural networks for liver trauma patients</title>
      <meta property="og:title" content="Prescriptive neural networks for liver trauma patients" />
			<meta charset="UTF-8">
  </head>

  <body>

		<div class="content-margin-container">
				<div class="margin-left-block">
				</div>
		    <div class="main-content-block">
						<table class="header" align=left>
								<tr>
									<td colspan=4>
										<span style="font-size: 32px; font-family: 'Courier New', Courier, monospace; /* Adds fallbacks */">Prescriptive neural networks for liver trauma patients</span>
									</td>
								</tr>
								<tr>
										<td align=left>
												<span style="font-size:17px"><a href="https://lisaxeverest.github.io">Lisa Everest</a></span>
										</td>
										<td align=left>
												<span style="font-size:17px"><a href="your_partner's_website">Carol (Xiaomiao) Gao</a></span>
										</td>
								<tr>
									<td colspan=4 align=left><span style="font-size:18px">Final project for 6.7960, MIT</span></td>
								</tr>
						</table>
					</div>
					<div class="margin-right-block">
					</div>
		</div>

		<div class="content-margin-container" id="intro">
				<div class="margin-left-block">
          <!-- table of contents here -->
          <div style="position:fixed; max-width:inherit; top:max(20%,120px)">
              <b style="font-size:16px">Outline</b><br><br>
              <a href="#intro">Introduction and Motivation</a><br><br>
              <a href="#related_work">Related work</a><br><br>
              <a href="#methodology">Methodology</a><br><br>
              <a href="#results">Results</a><br><br>
              <a href="#discussion">Discussion</a><br><br>
              <a href="#conclusion">Conclusion</a><br><br>
          </div>
				</div>
		    <div class="main-content-block">
            <!--You can embed an image like this:-->
            <img src="./images/liver-laceration-grades.png" width=512px/>
		    </div>
		    <div class="margin-right-block" >
					<p style = "color:#0e7862"><b>Figure 1:</b> Scans of the 5 grades of liver trauma <a href="https://www.researchgate.net/publication/361478611/figure/fig1/AS:1169964820119558@1655952758942/Different-types-of-liver-trauma-a1cm-depth-laceration-or-10-surface-area-haematoma.jpg">(credit)</a></p>
		    </div>
		</div>

    <div class="content-margin-container" id="intro">
				<div class="margin-left-block">
				</div>
		    <div class="main-content-block">
				<h2>Introduction and Motivation</h2>
				<p>
					With the increasing volume of data available, it has become more valuable and critical to utilize such resources 
					to develop data-driven algorithms that could guide personalized decision-making.
					Despite the fact that deep learning has primarily been used for prediction and classification tasks to improve accuracy,
					there could be substantial value added to such personalized prescription problems by leveraging 
					the high flexibility of neural networks to capture non-linear interactions between covariates 
					and combine different modalities of data such as tabular, language, and image data.
					Therefore, in this project, we try to combine optimization and deep learning to develop a neural network 
					that outputs prescriptions as a function of individual characteristics that optimize the desired objective. We will call 
					these neural networks Prescriptive Neural Networks (PNN)!
				</p>
				<p>
					Furthermore, we want to show how the PNN works on a real-world application in healthcare, since personalized decision-making is 
					very important in medicine; patients with different characteristics 
					might be handled differently in reality. Previous literature has demonstrated benefits of such personalized interventions in various
					medical settings. 
					<a href="#ref_readmission"> Bayati et al. (2014) </a> uses readmission predictions of heart failure patients to 
					guide individual treatment decisions post-discharge and show a reduction in both readmission rate and associated cost.
					<a href="#ref_diabetes"> Bertsimas et al. (2017) </a> leverage k-nearest neighbors to predict outcomes of type-2 diabetes patients
					under different combination of drugs and show that personalized management to diabete patients 
					yield major improvement in outcomes compared to the standard of care that does not differentiate.
				</p>
				<p>
					We have used a dataset on liver trauma injuries as our case study for how PNNs work in real-life. For liver injuries in particular, 
					the management of trauma patients is very important. 
					Acute liver injury is one of the two most common solid organ injuries in blunt trauma victims. 
					However, inaccuracies exist in the grading of liver injuries by human read and interpretation of CT scans, 
					which may lead to mistreatment <a href="#ref_3"> (Georg et al., 2014) </a>. In particular, severe liver lacerations tend to require surgeries, whereas less severe injuries 
					are usually treated with more conservative strategies. 
					Therefore, personalized treatment for the patient is important in trauma management, making this an appropriate and important
					motivating application to demonstrate our method.
				</p>
		    </div>
		    <!-- <div class="margin-right-block">
						Margin note that clarifies some detail #main-content-block for intro section.
		    </div> -->
		</div>

		<div class="content-margin-container" id="related_work">
				<div class="margin-left-block">
				</div>
		    <div class="main-content-block">
				<h2>Related work</h2>
				Let's look at some related work in this area!
				<p>	
					The most traditional method to personalized treatment is Regress and Compare in which a regression is trained on each set of training data by their treatment. 
					A given observation is then evaluated on models trained from all treatment options and the treatment that optimizes its outcome is selected. 
					<!-- However, the possible lack of data for each separate model and the lack of interpretability and may reduce the performance and applicability of this method.  -->
				</p>
				<p>
					In the past decade, tree-based machine learning methods and causal methods have sought to improve upon Regress and Compare. 
					For example, <a href="#ref_4"> Kallus (2017) </a> extends Regress and Compare and proposes a single-task method that recursively 
					partitions the input space with the smallest sum of impurities for prescription purposes. <a href="#ref_5"> Bertsimas et al. (2019) </a> 
					extends the Optimal Classification Trees in <a href="#ref_6"> Bertsimas and Dunn (2017) </a> - an interpretable tree-based method - to prescription. 
					They introduce Optimal Prescriptive Trees which estimates the counterfactual outcome of each observation under each treatment during training 
					to minimize both the prediction and the prescription error. Finally, <a href="#ref_7"> Amram et al. (2022) </a> further develops Optimal Policy Tree,
					where counterfactuals are estimated separately prior to the tree training. 
					A decision tree is then trained to obtain the optimal policy.
				</p>
				<p>	
					Even more recently, in the past year, there has been work on combining prescription and deep learning. 
					<a href="#ref_5"> Sun and Tsiourvas (2023) </a> proposes a prescriptive neural network model using ReLU as the activation function. 
					In particular, they partition the sample space into disjoint polyhedra and assign a treament to all data points that belong in each partition. 
					They further show that every such trained network can be transformed to a prescriptive tree with hyperplane splits. 
					<a href="#ref_6">Bergman et al. (2022) </a> formulates and solves an optimization problem using predictions obtained through a neural network in the objective function. 
					They also restrict to ReLU as the activation function to allow modelling as a network flow problem. 
					Relatedly, <a href="#ref_7">Patil et al. (2024)</a> formulates binary activation functions and loss function of neural networks
					as a mixed-integer programming problem, then combines with counterfactual estimation to obtain optimal treatments. 
				</p>
		    </div>
		    <div class="margin-right-block" style="transform: translate(0%, 70%);"> <!-- you can move the margin notes up and down with translate -->
				<p>	
					<b>So what's our contribution?</b> We attempt to contribute to the intersection of prescription and deep learning by relaxing 
					the restriction to ReLU or binary activation functions and 
					allowing any type of nonlinear activation functions in the neural network. 
					Moreover, we solve the prescription problem that optimizes the objective simultaneously as training the neural network. 
				</p>
		    </div>
		</div><div class="content-margin-container" id="Methodology">
			<div class="margin-left-block">
			</div>
		<div class="main-content-block">
				<h2>Methodology</h2>
				<p>
					Let's first learn about how our PNN model pipeline works. We define some notation that describes the data that characterizes 
					a prescription problem. The data is observational, in the form \( \{(\boldsymbol{x}_i, y_i, t_i)\}_{i=1}^n \), and 
					consists of the following components:
				</p>
				<ul>
					<li>
						<strong>Features.</strong> \( \boldsymbol{x}_i\in\mathbb{R}^p \) is the 
						\( p \)-dimensional feature data for the <em>i</em>-th observation. For our liver dataset, this includes patient 
						demographics, prior diagnoses, vitals, and clinical notes. We include some summary statistics of our features in 
						<a href="#figure2">Figure 2</a>.
					</li>
					<li>
						<strong>Treatments.</strong> \( t_i ∈ \{0,1\} \) is the treatment applied historically to the <em>i</em>-th 
						observation, where 0 indicates no treatment and 1 indicates surgical intervention (treatment). 
					</li>
					<li>
						<strong>Outcomes.</strong> \( y_i ∈ \{0,1\} \) is the result observed after treatment \( t_i \) has been
						 applied to the <em>i</em>-th observation, where 0 indicates patient survival and 1 indicates patient expiration.
					</li>
				</ul>

				<table>
					<caption id="figure2" style="color: #0e7862">
					</caption>
					<thead>
						<tr>
							<th>Feature Type </th>
							<th>Number of Columns</th>
						</tr>
					</thead>
					<tbody>
						<tr>
							<td>Prior Diagnoses and Procedures</td>
							<td>48</td>
						</tr>
						<tr>
							<td>Demographics (Age and Sex)</td>
							<td>2</td>
						</tr>
						<tr>
							<td>Vitals </td>
							<td>4</td>
						</tr>
						<tr>
							<td>Clinical Notes Embeddings</td>
							<td>768</td>
						</tr>
					</tbody>
				</table>
				
				We divide the training process into four main steps: 
				embedding extraction, counterfactual estimation, and 
				prescription policy learning (neural network training). <br><br>
				<h3>Embedding extraction </h3>
				Because our liver dataset is multimodal, the first step in the model pipeline is to extract embeddings each from the structured and unstructured data. <br>
				<h4>Structured data</h4> 
				We extract embeddings from structured feature data through traditional preprocessing techniques as 
				described below, where the technique depends on whether the feature is numerical, categorical, or ordinal.
				<ol>
					<li>
						<b>Numerical features.</b> We normalize numerical features to the interval [0,1] for the 
						counterfactual estimation and model training steps. This increases stability and helps to weight features equally!
					</li>
					<li>
						<b>Categorical features.</b> For categorical features, we use one-hot encodings to convert them to 
						binary features, such that each category becomes a new indicator feature.
					</li>
					<li><b>Ordinal features</b> Ordinal features are categorical features whose values carry numerical information. 
						Since these categories have a natural order to them, we can assign each category a number such as 1 to 5, 
						where relative magnitude holds information. For example, 
						a feature, "Age Groups", may take on the following values: "0-18", "19-24", "25-49", "50-74", "75-100"; we 
						can assign these to numbers 1 - 5, such that "0-18" is assigned 1, and so on. That way, an individual with an age of 
						"1" in the preprocessed data indicates that they are younger relative to an individual with an age of "3". 
						We then treat these ordinal features 
						as numerical features in our experiments.
					</li>
				</ol>
				<h4>Unstructured data</h4>
				<p>
					We extract embeddings from unstructured data using the pretrained model ClinicalLongformer, 
					a long sequence transformer model trained via a sparse attention mechanism on domain-specific, large-scale clinical corpora 
					<a href="#clinical_longformer">(Li et al., 2022)</a>; from this model, we obtain a 768-dimensional embedding vector for each observation's clinical note data. 
					However, this is a very high-dimensional input for training a neural network using only 722 datapoints (size of our liver dataset!). 
					In order to 
					improve stability, tractability, and performance, we  
					apply Principle Component Analysis (PCA) to reduce the dimensions of the clinical note embeddings. 
					We tried reducing to a 32-dimensional representation, and it works well for the liver trauma dataset.
				</p>
				<h3>Counterfactual estimation</h3>
				<p>
					Because the prescriptive problem's dataset only contains historical observational data, the counterfactuals are unknown, 
					e.g., the hypothetical outcomes \( y(\boldsymbol{x}_i, t) \) for \( t \neq t_{i} \). Thus, before model training, 
					we perform a counterfactual estimation step. This is something
					from the causal inference literature, and is a typical way of dealing with unknown outcomes! 
					Our approach is inspired by <a href="#ref-doubly-robust-policy">Dudik et al. (2014)</a>, 
					which estimates the outcomes for each observation under every treatment. Note that we can use purely tabular data or multimodal data to 
					estimate rewards!
				</p>

				<p>
					The goal of counterfactual estimation is to produce \( \Gamma \), a rewards matrix where each \( \Gamma_{i,t} \) is the estimated outcome of 
					applying treatment \( t \) to the \( i^{\text{th}} \) observation. We now review the 
					three main methods for counterfactual estimation:
				</p>
				<ol>
					<li>
						<b>Direct method.</b> T This is a method directly learns the outcome function \( y_{t}(\boldsymbol{x}) \)
						 by training separate models, one for each treatment \( t \). During training, each model uses 
						 only the subset of the observations that received treatment \( t \). 
						<!-- These models can be random forests or boosting methods and output an estimated outcome \( \hat{y_{t}}(\boldsymbol{x}) \) 
						for when treatment \( t \) is hypothetically applied to observation \( \boldsymbol{x} \). -->
					</li>
					<li>
						<b>Propensity score estimation.</b>  This is a method is used to calculate the probability \( p_{i,t} \) 
						that treatment \( t \) is assigned to observation \( i \). 
						The observational data \( \boldsymbol{x}_{i} \) is used to train a 
						classification model that predicts treatment assignments for each observation. 
						Then, using this model, the probability that each observation receives its prescribed treatment is calculated. 
						<!-- Here, random forests or boosting methods are also employed. -->
					</li>
					<li><b>Doubly robust estimation.</b> 
						Because direct estimation is often prone to treatment assignment bias, the doubly-robust 
						estimator is a method that attempts to mitigate this bias by re-weighting the estimated direct outcomes with 
						propensity score probabilities. 
						This reweighting is expressed as \( \Gamma \) below, in what we call the "reward matrix": 
						<p style="text-align: center;">
							\( \Gamma_{i,t} = \hat{y_{t}}(\boldsymbol{x}) + \frac{\mathbb{1}\{t = t_{i}\}}{p_{i,t}} \big(y_{i} - \hat{y_{t}}(\boldsymbol{x})\big). \)
						</p>
					</li>
				</ol>

				<h3>Prescription policy learning through feedforward neural networks</h3>
				<p>
					A feedforward neural network consists of layers of interconnected neurons, which are computational units that are 
					each characterized by weights 
					\( \{a_{i}\}_{i=1}^p \), a bias \( b \), and a nonlinear activation function \( h \). Given an input vector 
					\( \boldsymbol{x} \in \mathbb{R}^p \), the neuron calculates 
					\( y = \sum_{i=1}^{p}a_{i}x_{i} + b \), a weighted sum of the input's components, and passes the result \( y \) through 
					\( h \) to produce the neuron's output \( o = h(y) \) that serves as the input to the subsequent neuron. 
					As observational inputs \( \boldsymbol{x}_i \) pass through this network of interconnected neurons, this calculation is 
					performed in a nested manner, and the output of the final layer is computed, from which a prespecified loss function is 
					evaluated. Using backpropagation, the weights of the network are updated to minimize this loss function. The typical 
					structure is presented in <a href="#figure3">Figure 3</a>.
				</p>
				<h4 id="figure3" style="color: #0e7862">
					<!--<b>Figure 3: </b>Architecture of a Feedforward Neural Network (adapted from <a href="#ref_fnn">Quiza and Davim (2014)</a>]).-->
				</h4> 
				<figure>
					<img src="images/nn.png" alt="Feedforward Neural Network" style="width:60%;">
				</figure>
				<p>
					Since we want to minimize mortality risk in our liver dataset, our objective for the 
					prescriptive neural network is to minimize total rewards for the prescriptions \( \tau(\boldsymbol{x}_i) \) that are assigned to each 
					datapoint \( \boldsymbol{x}_i \) by the network:
				</p>
				<p style="text-align: center;">
					\( \min_{\tau(.)} \sum_{i=1}^{N} \sum_{t=1}^{N_t} \mathbb{1} \{\tau(\boldsymbol{x}_i) = t\} \cdot \Gamma_{i,t}. \)
				</p>
				<p>
					Because the indicator function is not differentiable, the backpropagation algorithm cannot exactly handle this objective. 
					So, we decide to "soften" the objective and leverage an approach analogous to that of multi-classification networks. As a result, the PNN assigns 
					treatments probabilistically, so that its output layer consists of \( N_t \) neurons, one for each distinct treatment. This is like how 
					multi-classification networks have an output corresponding to each target class! Let's denote the output vector of the PNN as 
					\( \boldsymbol{z} \in \mathbb{R}^{N_t} \). In the PNN, we apply a softmax activation function to these output neurons to obtain a probability 
					distribution over the distinct treatments, so that \( \mathbb{P}[\tau(\boldsymbol{x}_i) = t] = \sigma_t(\boldsymbol{z}) \), 
					where \( \sigma(\cdot) \) denotes the softmax function and is defined explicitly below:
				</p>
				<p style="text-align: center;">
					\( \sigma_t(\boldsymbol{z}) = \frac{\exp{z_{t}}}{\sum_{j=1}^{T} \exp{z_{j}}} \text{ for } t=1,\ldots,T \text{ and } \boldsymbol{z} 
					\in \mathbb{R}^T. \)
				</p>
				<p>
					We obtain the final prescription of the network by finding the treatment \( t \) with the highest probability 
					\( \mathbb{P}[\tau(\boldsymbol{x}_i) = t] = \sigma_t(\boldsymbol{z}) \). This approach is analogous to a classification network, 
					where the predicted class is the one with the highest probability among the network's output nodes. The tractable objective for 
					our PNN models is therefore:
				</p>
				<p style="text-align: center;">
					\( \min_{\tau(.)} \sum_{i=1}^{N} \sum_{t=1}^{T} \mathbb{P}[\tau(\boldsymbol{x}_i) = t] \cdot \Gamma_{i,t}. \)
				</p>
			</body>
		</div>

		<div class="margin-right-block" style="transform: translate(0%, -300%); color: #0e7862">
			<div style="transform: translate(0%, -3300%);" ><b>Figure 2:</b> Overview of Features</div>
			<div style="transform: translate(0%, 1600%);" ><b>Figure 3:</b> Typical structure of a feedforward neural network (adapted from <a href="#ref_fnn">Quiza and Davim (2014)</a>])</div>
		</div>
	</div>

		<!-- <div class="content-margin-container">
				<div class="margin-left-block">
				</div>
		    <div class="main-content-block">
            <h1>Experiments</h1>
            In this section we embed a video:
						<video class='my-video' loop autoplay muted style="width: 725px">
								<source src="./images/mtsh.mp4" type="video/mp4">
						</video>
		    </div>
		    <div class="margin-right-block">
					A caption for the video could go here.
		    </div>
		</div> -->

		<div class="content-margin-container" id="results">
				<div class="margin-left-block">
				</div>
		    <div class="main-content-block">
				<h2>Experiments and Results</h2>
				Now that we know what a PNN is and how to train one, we will present the experiment setup and results for our application on the liver trauma injury dataset.
				<!-- <a href="#table1">Table 1</a> summarizes the key statistics about the features present in the cohort. -->
 
				<h3>Data Split</h3>
				<p>
					For our experiments, we use the following data split: 50% for training and 50% for the test set. The typical ratios of 
					80-20 or 70-30 are not applicable in our prescriptive problem because we need to estimate counterfactuals for the test set 
					independently of the train set; this allows us to objectively and fairly evaluate the performance of the PNNs without 
					data leakage from the training set. Think about this: if we had estimated counterfactuals for the entire dataset altogether, then 
					there is leakage by training the PNN on the training set and evaluating it via the estimated rewards on the test set! And, to ensure 
					quality of estiamted counterfactuals, we need more data on both the test and training set. So a 50/50 split is necessary.
				</p>

				<h3>Network Architecture</h3>
				<p>
					For the PNN itself, we fine-tune the following hyperparameters:
				</p>
				<ul>
					<li><strong>Number of layers of the network.</strong> We experiment with both shallow and deep networks, and we generally observed
						that deeper networks do not necessarily improve prescriptive results.
					</li>
					<li><strong>Number of nodes at each layer.</strong> Because we use a relaively smaller dataset, we find that less layers are needed
						to train a good prescriptive model.
					</li>
					<li><strong>Batch size.</strong> This parameter determines the number of samples used in each forward pass of the network 
						and for backpropagation, where the network parameters are updated after each batch passes through the network. It also affects 
						the training speed, since too many batches can slow down the training process. Since we have less data, using a larger batch size
						is not necessarily a problem.
					</li>
					<li><strong>Learning rate.</strong> The learning rate is an important parameter of the training process, since it defines how 
						steep the descent is at each step of the gradient descent algorithm during training. After experimentation, 
						we find an appropriate learning rate that is not too big so that the algorithm becomes stuck in local optima but also not too 
						small so that convergence to the optimal value is too slow.
					</li>
					<li><strong>Weight decay.</strong> This hyperparameter scales an <code>L<sub>2</sub></code>-regularization term of the network weights that 
						is added to the objective function to prevent them from taking too large values. Since we normalize the data in the embedding extraction step, 
						we observe that 
						lowering the weight decay coefficient and relaxing the weights are actually beneficial and do not result in overfitting.
					</li>
					<li><strong>Number of epochs.</strong> The number of epochs is a particularly hard parameter to tune, since we want to prevent 
						overfitting but also allow the training to continue until sufficient convergence. For this reason, we employ early stopping, 
						a technique that is adaptive to each specific training process and terminates training when a fluctuation in the validation 
						loss is observed. Such a fluctuation indicates that the network is no longer improving in out-of-sample data generalization.
					</li>
				</ul>
				<p>
					On top of these architectural choices, we choose the Adam optimizer. We tune the aforementioned hyperparameters using a 
					validation set we extract from the training set that is not used in model training. We typically keep 15% of the training 
					data for the validation set. 
				</p>
				<h3>Performance evaluation</h3>
				<p>
				<a href="#figure4">Figure 4</a> plots the training and validation losses for one of a sample PNN.We can see how the early stopping is helpful in 
				terminating the training process when validation loss is no longer improving significantly, helping to prevent overfitting! 
				</p>	
				<h4 id="figure4" style="color: #0e7862">
				</h4>
				<figure>
					<img src="images/training_curve.png" alt="training curve" style="width:60%;">
				</figure>
				<p>
					To evaluate the PNN performance on the liver dataset, we perform multiple train-validation-test splits and report 
					the average performance of each split's models. This ensures that the results are not tailored to a specific data 
					split. Also, given the randomness often 
					associated with training machine learning models, we train multiple models per split and also average their performance. 
					In total, we perform 5 randomized data splits per dataset; for each split, we train 5 iterations of 5 models each for a total of 125 
					individual models per seed. For each iteration,
					we also ensemble the 5 respective models using a hard-voting framework, for a total of 25 ensembles per seed. 
				</p>
				<p>
					Furthermore, since the feature embeddings are easily modularized, we train two types of models: a tabular model trained 
					on only the tabular features, and a multimodal model trained on concatenated tabular and notes features. Since the tabular model is trained 
					using only the tabular features, it is natural that the counterfactual rewards it uses to train is also only estimated on the tabular features.
					A similar approach is used for the multimodal model as well.  
				</p>
				<p>
					We present the 
					results of the 125 individual models and 25 
					ensemble models in <a href="#figure5">Figure 5</a>. In this table, the numbers are the improvement for all models for each seed, 
					as well as the average across seeds, in <a href="#figure5">Figure 5</a>. The improvement 
					is the total estimated counterfactual rewards of the PNN prescriptions relative to the total estimated rewards 
					of the prescriptions in reality. Because of how the tabular and multimodal models are trained (one on tabular counterfactuals and one 
					on multimodal counterfactuals), it is only fair that we compare model improvement in both types of estimators: the 
					"Tabular" estimator and the "Tabular & Notes" (multimodal) 
					estimator. 
				</p>
				
				<table>
					<caption id="figure5" style="color: #0e7862">
					</caption>
					<!-- <caption>
						Improvement in mortality risk for the experiment on liver trauma injuries, where lower mortality is better.
						Within each split, we report the average improvement and standard deviation across five iterations. For the average 
						split results, we report the average improvement and standard deviation across the five splits.
					</caption> -->
					<thead>
						<tr>
							<th>Estimator</th>
							<th>Split</th>
							<th>Method</th>
							<th>Tabular model</th>
							<th>Multimodal model</th>
						</tr>
					</thead>
					<tbody>
						<!-- Tabular Estimator -->
						<tr>
							<td rowspan="12">Tabular</td>
							<td rowspan="2">1</td>
							<td>PNN</td>
							<td>0.0833 ± 0.1561</td>
							<td>0.0667 ± 0.1959</td>
						</tr>
						<tr>
							<td>Ensemble PNN</td>
							<td>0.2558 ± 0.0679</td>
							<td>0.1882 ± 0.1304</td>
						</tr>
						<tr>
							<td rowspan="2">2</td>
							<td>PNN</td>
							<td>0.1485 ± 0.1713</td>
							<td>0.3957 ± 0.1777</td>
						</tr>
						<tr>
							<td>Ensemble PNN</td>
							<td>0.1789 ± 0.1298</td>
							<td>0.4974 ± 0.0659</td>
						</tr>
						<tr>
							<td rowspan="2">3</td>
							<td>PNN</td>
							<td>-0.1718 ± 0.2931</td>
							<td>-0.0035 ± 0.1806</td>
						</tr>
						<tr>
							<td>Ensemble PNN</td>
							<td>-0.0459 ± 0.1679</td>
							<td>0.2119 ± 0.0673</td>
						</tr>
						<tr>
							<td rowspan="2">4</td>
							<td>PNN</td>
							<td>0.2097 ± 0.1768</td>
							<td>0.2872 ± 0.0962</td>
						</tr>
						<tr>
							<td>Ensemble PNN</td>
							<td>0.3319 ± 0.0782</td>
							<td>0.3805 ± 0.0298</td>
						</tr>
						<tr>
							<td rowspan="2">5</td>
							<td>PNN</td>
							<td>0.1016 ± 0.1697</td>
							<td>0.4766 ± 0.0707</td>
						</tr>
						<tr>
							<td>Ensemble PNN</td>
							<td>0.212 ± 0.1018</td>
							<td>0.5024 ± 0.0157</td>
						</tr>
						<tr>
							<td rowspan="2">Average</td>
							<td>PNN</td>
							<td>0.0743 ± 0.1460</td>
							<td>0.2445 ± 0.2072</td>
						</tr>
						<tr>
							<td>Ensemble PNN</td>
							<td>0.1865 ± 0.1420</td>
							<td><strong>0.3561 ± 0.1508</strong></td>
						</tr>
						<!-- Tabular & Notes Estimator -->
						<tr>
							<td rowspan="12">Tabular &amp; Notes</td>
							<td rowspan="2">1</td>
							<td>PNN</td>
							<td>0.2202 ± 0.2257</td>
							<td>0.2141 ± 0.1721</td>
						</tr>
						<tr>
							<td>Ensemble PNN</td>
							<td>0.3682 ± 0.0721</td>
							<td>0.4268 ± 0.0314</td>
						</tr>
						<tr>
							<td rowspan="2">2</td>
							<td>PNN</td>
							<td>0.2041 ± 0.1229</td>
							<td>0.4107 ± 0.0664</td>
						</tr>
						<tr>
							<td>Ensemble PNN</td>
							<td>0.1822 ± 0.1114</td>
							<td>0.4623 ± 0.062</td>
						</tr>
						<tr>
							<td rowspan="2">3</td>
							<td>PNN</td>
							<td>0.2374 ± 0.1872</td>
							<td>0.2933 ± 0.0978</td>
						</tr>
						<tr>
							<td>Ensemble PNN</td>
							<td>0.4283 ± 0.0558</td>
							<td>0.423 ± 0.048</td>
						</tr>
						<tr>
							<td rowspan="2">4</td>
							<td>PNN</td>
							<td>0.1743 ± 0.211</td>
							<td>0.1572 ± 0.162</td>
						</tr>
						<tr>
							<td>Ensemble PNN</td>
							<td>0.3326 ± 0.0415</td>
							<td>0.3364 ± 0.081</td>
						</tr>
						<tr>
							<td rowspan="2">5</td>
							<td>PNN</td>
							<td>0.2725 ± 0.1439</td>
							<td>0.6307 ± 0.0417</td>
						</tr>
						<tr>
							<td>Ensemble PNN</td>
							<td>0.3953 ± 0.037</td>
							<td>0.6424 ± 0.0078</td>
						</tr>
						<tr>
							<td rowspan="2">Average</td>
							<td>PNN</td>
							<td>0.2217 ± 0.0367</td>
							<td>0.3412 ± 0.1877</td>
						</tr>
						<tr>
							<td>Ensemble PNN</td>
							<td>0.3413 ± 0.0957</td>
							<td><strong>0.4582 ± 0.1129</strong></td>
						</tr>
					</tbody>
				</table>
				
		    </div>
			<div class="margin-right-block" style="transform: translate(0%, -300%); color: #0e7862">
				<div style="transform: translate(0%, -300%);" ><b>Figure 4:</b> Training and Validation Losses </div>
				<div style="transform: translate(0%, 2300%);" ><b>Figure 5:</b> Average Improvement in Mortality Risk of Liver Trauma Patients </div>
			</div>
		</div>

		<!-- <div class="content-margin-container" >	
			<div class="margin-left-block">
			</div>		
		    <div class="main-content-block">
		</div> -->


		<div class="content-margin-container" id="discussion">
			<div class="margin-left-block">
				</div>
		    <div class="main-content-block">
				<h2>Discussion</h2>
				<p>
					We find that both the PNN and ensembled PNN models are able to succesfully decrease (improve) mortality rate, with the 
					ensemble models outperforming the individual PNN models! Furthermore, we also find that within each random data split, the 
					ensemble model is much more stable than the individual models; both for the tabular 
					models and particularly for the multimodal models within each seed in <a href="#figure5">Figure 5</a> , the standard deviation of the 
					ensemble PNN is at most half that of the individual PNN -- sometimes almost an order of magnitude smaller. 
				</p>

				<p>
					Finally, the multimodal (tabular and note) models outperform their tabular counterparts, demonstrating the benefit of 
					increased information from the added language modality.
				</p>
		    </div>
		    <div class="margin-right-block">
		    </div>
		</div>

		<div class="content-margin-container" id="conclusion">
				<div class="margin-left-block">
				</div>
		    <div class="main-content-block">
				<h2>Conclusion</h2>
				<p>
					Methodologically, with its classification-like feedforward neural network architecture, our PNN models flexibly handle multimodal and unimodal data 
					as well as any nonlinear activation function. Furthermore, PNN holistically combines prediction and prescription in one step. Empirically, they 
					demonstrate wide applicability in healthcare and have the potential of making 
					a significant impact in a variety of settings. As shown in our liver trauma management experiments where correct and in-time prescription
					is critical to patient outcomes, PNN and ensembled PNN using clinical notes and tabular features reduce mortality rate by as much as 0.46. 
					We even showed some potential in ensembling the PNNs to produce both higher performance as well as increased stability. 
				</p>
				<p>
					As next steps, we are interested in comparing the performance of our method with other prescriptive methods that 
					leverage neural networks. In addition, we would like to empirically test this method on other applications. 
				</p>
		    </div>
		    <div class="margin-right-block">
		    </div>
		</div>

		<div class="content-margin-container" id="citations">
				<div class="margin-left-block">
				</div>
		    <div class="main-content-block">
						<div class='citation' id="references" style="height:auto"><br>
							<span style="font-size:16px">References:</span><br><br>
							<a id="ref_readmission"></a>[1]
								Bayati, Mohsen, et al. 
    							<cite>Data-Driven Decisions for Reducing Readmissions for Heart Failure: General Methodology and Case Study.</cite> 
    							<i>PloS One</i>, vol. 9, no. 10, 2014, e109264.
							<br><br>
							<a id="ref_diabetes"></a>[2]
								Bertsimas, Dimitris, et al. 
    							<cite>Personalized Diabetes Management Using Electronic Medical Records.</cite> 
    							<i>Diabetes Care</i>, vol. 40, no. 2, 2017, pp. 210–217.
							<br><br>
							<a id="ref_3"></a>[3]
								Homann, Georg, et al. 
    							<cite>Accuracy of the AAST Organ Injury Scale for CT Evaluation of Traumatic Liver and Spleen Injuries.</cite> 
    							<i>Chinese Journal of Traumatology</i>, vol. 17, no. 1, 2014, pp. 25–30.
							<br><br>
							<a id="ref_4"></a>[4]
								Kallus, Nathan. 
								<cite>Recursive Partitioning for Personalization Using Observational Data.</cite> 
								<i>International Conference on Machine Learning</i>, PMLR, 2017.
							<br><br>
							<a id="ref_5"></a>[5]
								Bertsimas, Dimitris, Jack Dunn, and Nishanth Mundru. 
    							<cite>Optimal Prescriptive Trees.</cite> 
    							<i>INFORMS Journal on Optimization</i>, vol. 1, no. 2, 2019, pp. 164–183.
							<br><br>
							<a id="ref_6"></a>[6]
								Bertsimas, Dimitris, and Jack Dunn. 
								<cite> Optimal classification trees.</cite>
								<i>Machine Learning</i>, vol. 106, 2017, pp. 1039–1082.
							<br><br>
							<a id="ref_7"></a>[7]
								Amram, Maxime, Jack Dunn, and Ying Daisy Zhuo. 
								<cite>Optimal Policy Trees.</cite> 
								<i>Machine Learning</i>, vol. 111, no. 7, 2022, pp. 2741–2768.
							<br><br>
							<a id="ref_8"></a>[8]
								Sun, Wei, and Asterios Tsiourvas. 
								<cite>Learning Prescriptive ReLU Networks.</cite> 
								<i>International Conference on Machine Learning</i>, PMLR, 2023.
							<br><br>
							<a id="ref_9"></a>[9]
								Bergman, David, et al. 
								<cite>JANOS: An Integrated Predictive and Prescriptive Modeling Framework.</cite> 
								<i>INFORMS Journal on Computing</i>, vol. 34, no. 2, 2022, pp. 807–816.
							<br><br>
							<a id = "ref_10"></a>[10]
								Patil, Vrishabh, Kara Hoppe, and Yonatan Mintz. 
								<cite>Applications of 0-1 Neural Networks in Prescription and Prediction.</cite> 
								<i>arXiv preprint</i>, arXiv:2402.18851, 2024.
							<br><br>
							<a id = "ref-doubly-robust-policy"></a>[11]
								Dudík, Miroslav, John Langford, and Lihong Li. 
    							<cite>Doubly Robust Policy Evaluation and Learning.</cite> 
    							<i>arXiv preprint</i>, arXiv:1103.4601, 2011.
							<br><br>
							<a id = "clinical_longformer"></a>[12]
								Li, Yikuan, Ramsey M. Wehbe, Faraz S. Ahmad, Hanyin Wang, and Yuan Luo. 
    							<cite>Clinical-Longformer and Clinical-BigBird: Transformers for Long Clinical Sequences.</cite> 
    							<i>arXiv preprint</i>, arXiv:2201.11838, 2022.
							<br><br>
							<a id = "ref_fnn"></a>[13]
								Quiza, Ramon, and J. Paulo Davim. 
								<cite>Computational Methods and Optimization.</cite> 
								<i>Machining of Hard Materials</i>, Springer, 2011, pp. 177–208.
							<br><br>
						</div>
		    </div>
		    <div class="margin-right-block">
            <!-- margin notes for reference block here -->
		    </div>
		</div>

	</body>

</html>
